las-pyramidal-kmeans-acoustics-debug: !Experiment
  exp_global: !ExpGlobal
    dropout: 0.3
    default_layer_dim: 512
    placeholders:
      DATA_DIR: /home/jialu/TIMIT
  # preproc: !PreprocRunner
  #   overwrite: False
  #   tasks:
  #   - !PreprocExtract
  #     in_files:
  #     - '{DATA_DIR}/db/dev.yaml'
  #     - '{DATA_DIR}/db/test.yaml'
  #     - '{DATA_DIR}/db/train.yaml'
  #     out_files:
  #     - '{DATA_DIR}/feat/dev.h5'
  #     - '{DATA_DIR}/feat/test.h5'
  #     - '{DATA_DIR}/feat/train.h5'
  #     specs: !MelFiltExtractor {}
  model: !DefaultKMeansTranslator
    src_embedder: !NoopEmbedder
      emb_dim: 40
    encoder: !ModularSeqTransducer
      modules:
      - !PyramidalLSTMSeqTransducer
        layers: 4
        reduce_factor: 2
        downsampling_method: concat
        input_dim: 40
        hidden_dim: 512
    attender: !MlpAttender
      hidden_dim: 128
    trg_embedder: !SimpleWordEmbedder
      emb_dim: 64
      word_dropout: 0.1
      fix_norm: 1
    decoder: !AutoRegressiveDecoder
      rnn: !UniLSTMSeqTransducer
        layers: 1
        hidden_dim: 512
      input_feeding: True
      bridge: !CopyBridge {}
      scorer: !Softmax
        label_smoothing: 0.1
    src_reader: !H5Reader
      transpose: true
    trg_reader: !PlainTextReader
      vocab: !Vocab
        vocab_file: '{EXP_DIR}/vocab.char'
    cluster: !KMeans
      n_dims: 40
      n_components: 100
      max_iter: 20
  train: !SimpleTrainingRegimen
    src_file: '{DATA_DIR}/train.h5'
    trg_file: '{DATA_DIR}/train.char'
    max_src_len: 1500
    max_trg_len: 350
    run_for_epochs: 20
    batcher: !WordSrcBatcher
      avg_batch_size: 220
      pad_src_to_multiple: 8
      src_pad_token: ~
    loss_calculator: !AutoRegressiveKMeansLoss
      truncate_dec_batches: false
      dev_evaluate: false
      test_evaluate: false
    trainer: !AdamTrainer
      alpha: 0.001
    lr_decay: 0.5
    lr_decay_times: 3
    patience: 8
    initial_patience: 15
    dev_every: 0
    restart_trainer: True
    dev_tasks:
      - !AccuracyEvalTask
        eval_metrics: wer,cer
        src_file: &dev_src '{DATA_DIR}/dev.h5'
        ref_file: '{DATA_DIR}/dev.words'
        hyp_file: '{EXP_DIR}/logs/{EXP}.dev_hyp'
        inference: !AutoRegressiveInference
          batcher: !InOrderBatcher
            batch_size: 1
            pad_src_to_multiple: 8
            src_pad_token: ~
          max_src_len: 1500
          post_process: join-char
          search_strategy: !BeamSearch
            max_len: 500
            beam_size: 20
            len_norm: !PolynomialNormalization
              apply_during_search: true
              m: 1.5
      - !LossEvalTask
        loss_calculator: !AutoRegressiveKMeansLoss
          truncate_dec_batches: false
          dev_evaluate: true
          test_evaluate: false
        max_src_len: 1500
        src_file: *dev_src
        ref_file: '{DATA_DIR}/dev.char'
  evaluate:
    - !AccuracyEvalTask
      eval_metrics: wer,cer
      src_file: '{DATA_DIR}/test.h5'
      ref_file: '{DATA_DIR}/test.words'
      hyp_file: '{EXP_DIR}/logs/{EXP}.test_hyp'
      inference: !AutoRegressiveInference
        batcher: !InOrderBatcher
          batch_size: 1
          pad_src_to_multiple: 8
          src_pad_token: ~
        max_src_len: 1500
        post_process: join-char
        search_strategy: !BeamSearch
          max_len: 500
          beam_size: 20
          len_norm: !PolynomialNormalization
            apply_during_search: true
            m: 1.5
    - !LossEvalTask
      loss_calculator: !AutoRegressiveKMeansLoss
        truncate_dec_batches: false
        dev_evaluate: false
        test_evaluate: true
      max_src_len: 1500
      src_file: '{DATA_DIR}/test.h5'
      ref_file: '{DATA_DIR}/test.char'

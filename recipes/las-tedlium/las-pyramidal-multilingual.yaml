las-pyramidal-multilingual: !Experiment
  exp_global: !ExpGlobal
    dropout: 0.3
    default_layer_dim: 512
    placeholders:
      #ENG_DATA_DIR: /home/jialu/TIMIT
      ENG_DATA_DIR: /home/jialu/tedlium/tedlium2
      CHI_DATA_DIR: /home/jialu/mandarin_dataset/data
  # preproc: !PreprocRunner
  #   overwrite: False
  #   tasks:
  #   - !PreprocExtract
  #     in_files:
  #     - '{DATA_DIR}/db/dev.yaml'
  #     - '{DATA_DIR}/db/test.yaml'
  #     - '{DATA_DIR}/db/train.yaml'
  #     out_files:
  #     - '{DATA_DIR}/feat/dev.h5'
  #     - '{DATA_DIR}/feat/test.h5'
  #     - '{DATA_DIR}/feat/train.h5'
  #     specs: !MelFiltExtractor {}
  train: !SameBatchMultiTaskTrainingRegimen
    trainer: !AdamTrainer {alpha: 0.001}
    #n_task_steps: [1,1]
    dev_zero: True
      #alpha: 0.001
    tasks:
    - !SimpleTrainingTask
      name: english_task
      max_src_len: 1500
      max_trg_len: 350
      run_for_epochs: 1
      lr_decay: 0.5
      lr_decay_times: 3
      patience: 8
      initial_patience: 15
      dev_every: 1
      restart_trainer: True
      batcher: !WordSrcBatcher
        avg_batch_size: 50
        pad_src_to_multiple: 8
        src_pad_token: ~
      src_file: '{ENG_DATA_DIR}/feat/train0.h5'
      trg_file: '{ENG_DATA_DIR}/transcript/train0.char'
      dev_tasks:
        - !AccuracyEvalTask
          model: !Ref {name: mandarin_model}
          eval_metrics: wer,cer
          src_file: &eng_dev_src '{ENG_DATA_DIR}/feat/dev.h5'
          ref_file: '{ENG_DATA_DIR}/transcript/dev.words'
          hyp_file: '{EXP_DIR}/logs/{EXP}.eng_dev_hyp'
          inference: !AutoRegressiveInference
            batcher: !InOrderBatcher
              batch_size: 1
              pad_src_to_multiple: 8
              src_pad_token: ~
            max_src_len: 1500
            post_process: join-char
            search_strategy: !BeamSearch
              max_len: 500
              beam_size: 20
              len_norm: !PolynomialNormalization
                apply_during_search: true
                m: 1.5
        - !LossEvalTask
          model: !Ref {name: english_model}
          max_src_len: 1500
          src_file: *eng_dev_src
          ref_file: '{ENG_DATA_DIR}/transcript/dev.char'
      model: !DefaultTranslator
        _xnmt_id: english_model
        src_embedder: !NoopEmbedder
          emb_dim: 40
        encoder: !ModularSeqTransducer
          _xnmt_id: shared_encoder
          modules:
            - !PyramidalLSTMSeqTransducer
              layers: 4
              reduce_factor: 2
              downsampling_method: concat
              input_dim: 40
              hidden_dim: 512
        attender: !MlpAttender
          hidden_dim: 128
        trg_embedder: !SimpleWordEmbedder
          emb_dim: 64
          word_dropout: 0.1
          fix_norm: 1
          vocab: !Ref {name: trg_eng_vocab}
        decoder: !AutoRegressiveDecoder
          rnn: !UniLSTMSeqTransducer
            layers: 1
            hidden_dim: 512
          input_feeding: True
          bridge: !CopyBridge {}
          scorer: !Softmax
            vocab: !Ref {name: trg_eng_vocab}
            label_smoothing: 0.1
        src_reader: !H5Reader
          transpose: true
        trg_reader: !PlainTextReader
          vocab: !Vocab
            _xnmt_id: trg_eng_vocab
            vocab_file: '{EXP_DIR}/vocab.char'
    - !SimpleTrainingTask
      name: mandarin_task
      max_src_len: 1500
      max_trg_len: 350
      run_for_epochs: 1
      lr_decay: 0.5
      lr_decay_times: 3
      patience: 8
      initial_patience: 15
      dev_every: 1
      restart_trainer: True
      batcher: !WordSrcBatcher
        avg_batch_size: 50
        pad_src_to_multiple: 8
        src_pad_token: ~
      src_file: '{CHI_DATA_DIR}/train0.h5'
      trg_file: '{CHI_DATA_DIR}/train0.char'
      dev_tasks:
        - !AccuracyEvalTask
          model: !Ref {name: mandarin_model}
          eval_metrics: wer,cer
          src_file: &chi_dev_src '{CHI_DATA_DIR}/dev.h5'
          ref_file: '{CHI_DATA_DIR}/dev.words'
          hyp_file: '{EXP_DIR}/logs/{EXP}.chi_dev_hyp'
          inference: !AutoRegressiveInference
            batcher: !InOrderBatcher
              batch_size: 1
              pad_src_to_multiple: 8
              src_pad_token: ~
            max_src_len: 1500
            post_process: join-char
            search_strategy: !BeamSearch
              max_len: 500
              beam_size: 20
              len_norm: !PolynomialNormalization
                apply_during_search: true
                m: 1.5
        - !LossEvalTask
          model: !Ref {name: mandarin_model}
          max_src_len: 1500
          src_file: *chi_dev_src
          ref_file: '{CHI_DATA_DIR}/dev.char'
      model: !DefaultTranslator
        _xnmt_id: mandarin_model
        src_embedder: !NoopEmbedder
          emb_dim: 40
        encoder: !Ref {name: shared_encoder}
        attender: !MlpAttender
          hidden_dim: 128
        trg_embedder: !SimpleWordEmbedder
          emb_dim: 64
          word_dropout: 0.1
          fix_norm: 1
          vocab: !Ref {name: trg_chi_vocab}
        decoder: !AutoRegressiveDecoder
          rnn: !UniLSTMSeqTransducer
            layers: 1
            hidden_dim: 512
          input_feeding: True
          bridge: !CopyBridge {}
          scorer: !Softmax
            vocab: !Ref {name: trg_chi_vocab}
            label_smoothing: 0.1
        src_reader: !H5Reader
          transpose: true
        trg_reader: !PlainTextReader
          vocab: !Vocab
            _xnmt_id: trg_chi_vocab
            vocab_file: '{EXP_DIR}/chineseVocab.char'
  evaluate: #used for development test
    - !AccuracyEvalTask
      model: !Ref { name: english_model }
      eval_metrics: wer,cer
      src_file: '{ENG_DATA_DIR}/feat/test.h5'
      ref_file: '{ENG_DATA_DIR}/transcript/test.words'
      hyp_file: '{EXP_DIR}/logs/{EXP}.eng_test_hyp'
      inference: !AutoRegressiveInference
        batcher: !InOrderBatcher
          batch_size: 1
          pad_src_to_multiple: 8
          src_pad_token: ~
        max_src_len: 1500
        post_process: join-char
        search_strategy: !BeamSearch
          max_len: 500
          beam_size: 20
          len_norm: !PolynomialNormalization
            apply_during_search: true
            m: 1.5
    - !AccuracyEvalTask
      model: !Ref { name: mandarin_model }
      eval_metrics: wer,cer
      src_file: '{CHI_DATA_DIR}/test.h5'
      ref_file: '{CHI_DATA_DIR}/test.words'
      hyp_file: '{EXP_DIR}/logs/{EXP}.chi_test_hyp'
      inference: !AutoRegressiveInference
        batcher: !InOrderBatcher
          batch_size: 1
          pad_src_to_multiple: 8
          src_pad_token: ~
        max_src_len: 1500
        post_process: join-char
        search_strategy: !BeamSearch
          max_len: 500
          beam_size: 20
          len_norm: !PolynomialNormalization
            apply_during_search: true
            m: 1.5
